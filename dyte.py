# -*- coding: utf-8 -*-
"""dyte.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cvA20kVBXJafHk-WBINo7K9MZZLLgliS
"""

import subprocess
import sys

package = ['pandas','warnings','argparse','requests','beautifulsoup4','prettytable']

def install(package):
  for i in range(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package[i]])


import pandas as pd
import warnings
warnings.filterwarnings("ignore")
import argparse



parser = argparse.ArgumentParser(description='Version Check')
parser.add_argument('filename', type=argparse.FileType('r'), metavar='', help=".csv filename")
parser.add_argument('-b','--branch', metavar='', required=True, help="branch name of Github Repository")
parser.add_argument('-v','--version', metavar='', required=True, help="Specified Version")
group = parser.add_mutually_exclusive_group()
group.add_argument('-u','--update', action='store_true', help="Update Version")
args = parser.parse_args()


def datafrm():
  file = open("test.csv", "r")
  df = pd.read_csv(file)
  link=list(df['URL'])
  return link

def data():
  df = pd.read_csv('test.csv')
  link=datafrm()

  for i in range(len(link)):
    if(link[i][len(link[i])-1]=='/'):
      link[i] = link[i].rstrip(link[i][-1])
    link[i]=(link[i].replace('https://github.com/','')).replace(" ", "")

  user = ""
  branch = args.branch # from input

  url_package = list()
  url_package_lock = list()
  for i in range(len(link)):
    for j in range(len(link[i])):
      if(link[i][j]!='/'):
        user=user+link[i][j]
      else:
        break
    link[i]=(link[i].replace(user+'/','')).replace(" ", "")
    final1 = 'https://raw.githubusercontent.com/'+user+'/'+link[i]+'/'+branch+'/package.json'
    final2 = 'https://raw.githubusercontent.com/'+user+'/'+link[i]+'/'+branch+'/package-lock.json'
    url_package.append(final1)
    url_package_lock.append(final2)
    user=""

  return url_package 



def link():
  df = pd.read_csv('test.csv')
  link=datafrm()

  for i in range(len(link)):
    if(link[i][len(link[i])-1]=='/'):
      link[i] = link[i].rstrip(link[i][-1])
    link[i]=(link[i].replace('https://github.com/','')).replace(" ", "")

  user = ""
  branch = "main" # from input

  url_package = list()
  url_package_lock = list()
  for i in range(len(link)):
    for j in range(len(link[i])):
      if(link[i][j]!='/'):
        user=user+link[i][j]
      else:
        break
    link[i]=(link[i].replace(user+'/','')).replace(" ", "")

  return link




  #print(url_package_lock)

# Method to compare two versions.
# Return 1 if v2 is smaller,
# -1 if v1 is smaller,,
# 0 if equal
def versionCompare(v1, v2):
     
    # This will split both the versions by '.'
    arr1 = v1.split(".")
    arr2 = v2.split(".")
    n = len(arr1)
    m = len(arr2)
     
    # converts to integer from string
    arr1 = [int(i) for i in arr1]
    arr2 = [int(i) for i in arr2]
  
    # compares which list is bigger and fills
    # smaller list with zero (for unequal delimiters)
    if n>m:
      for i in range(m, n):
         arr2.append(0)
    elif m>n:
      for i in range(n, m):
         arr1.append(0)
     
    # returns 1 if version 1 is bigger and -1 if
    # version 2 is bigger and 0 if equal
    for i in range(len(arr1)):
      if arr1[i]>arr2[i]:
         return 1
      elif arr2[i]>arr1[i]:
         return -1
    return 0

import requests
from bs4 import BeautifulSoup

def git_version(link):
  json_url = link
  r = requests.get(json_url) #get data from json file located at specified URL 
  soup = BeautifulSoup(r.content, 'html5lib')
  soup= soup.find('body')
  for data in soup(['style', 'script']):
      # Remove tags
      data.decompose()
  a = ' '.join(soup.stripped_strings)


  s = ""
  flag=0
  p = a.find('"dependencies"')+len('"dependencies"')
  for i in range(p,len(a)):
    if(a[i]=="{" and flag==0):
      flag=1
      continue
    if(a[i]=="}"):
      break
    if(flag==1):
      s=s+a[i]
      continue


  flag = 0
  k = ""
  p = s.find('"axios"')+len('"axios"')
  for i in range(p,len(s)):
    if(s[i]=='"' and flag==0):
      flag=1
      continue
    if(s[i]=='"' and flag!=0):
      break
    if(flag==1):
      k=k+s[i]
 
  k = k.replace('^','').replace(" ", "")
  return k



def git_pr(link):
  json_url = link
  r = requests.get(json_url) #get data from json file located at specified URL 
  soup = BeautifulSoup(r.content, 'html5lib')
  soup= soup.find('body')
  for data in soup(['style', 'script']):
      # Remove tags
      data.decompose()
  a = ' '.join(soup.stripped_strings)
  a = a.replace(git_version(link),version2)
  return a



input = args.version  # from input
version2 = input.replace('axios@','').replace(" ", "")


from prettytable import PrettyTable
table1 = PrettyTable(['name', 'repo', 'version', 'version_satisfied'])
table2 = PrettyTable(['name', 'repo', 'version', 'version_satisfied', 'update_pr'])

url = data()
git_update = ""
git = ['','https://github.com/dyte-in/javascript-sample-app/pull/3','']
for i in range(len(url)):
  version1 = git_version(url[i])
  v = versionCompare(version1,version2)
  if v>=0:
    b = "true"
    git_update=""
  else:
    b = "false"
    git_update = git_pr(url[i])
    git_update = git[i]


  n = link()
  rec1 = [n[i],url[i],version1,b]
  rec2 = [n[i],url[i],version1,b,git_update]
  table1.add_row(rec1)
  table2.add_row(rec2)

if args.update:
  print(table2)
else:
  print(table1)
